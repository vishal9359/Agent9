"""
Agent9 - C++ function flowchart generator (AST-driven, low-hallucination)

Major goals (from requirements):
- Work on any C/C++ project: use libclang AST to parse.
- Generate a JSON list per parsed file with: name, location, description, mermaid flowchart, image path.
- Flowchart must be logically correct (control flow), valid Mermaid, and include function calls as black boxes.
- Do NOT go inside callees.
- Use open-source LLM via Ollama (ChatOllama).

Key approach to reduce hallucinations on large functions (300-600+ lines):
- AST deterministically defines control-flow (if/loop/switch/try/return/break/continue).
- LLM is used ONLY to summarize *small* basic blocks (<= MAX_BLOCK_LINES lines) into short labels.
- Mermaid is composed by this code (not generated by LLM).
"""

from __future__ import annotations

import argparse
import json
import os
import re
import subprocess
from collections import defaultdict
from dataclasses import dataclass
from typing import Optional

from clang import cindex
from docx import Document
from docx.shared import Inches
from langchain.messages import HumanMessage
from langchain_ollama import ChatOllama
from enum import Enum


# OPTIONAL: Set explicitly if needed
# cindex.Config.set_library_file("/usr/lib/llvm-18/lib/libclang.so")

SUPPORTED_EXT = (".c", ".cpp", ".cc", ".cxx")

# Paths (update for your environment)
mermaid_path = "/home/workspace/mermaid_converter"
out_dir = "/home/workspace/adk/gemma-code/orchestrator/docs"

# LLM (open-source) via Ollama
llm = ChatOllama(model="gpt-oss", temperature=0.2, top_k=10, top_p=0.9)

# Chunking/safety limits
MAX_BLOCK_LINES = 80        # max lines per LLM block summary
MAX_LABEL_CHARS = 80        # max label length in Mermaid
MAX_SUMMARY_RETRIES = 3     # per block summary

# Flowchart granularity / aggregation
PENDING_SEGMENT_MAX_LINES = 20   # split long straight-line code into segments before LLM summary
PENDING_SEGMENT_MAX_STMTS = 6    # upper bound on statements per segment
MAX_REGION_NODES = 4             # max basic-block nodes merged into one semantic region
REGION_NAME_WORDS_MIN = 3
REGION_NAME_WORDS_MAX = 6


def _ck(name: str):
    """
    Return cindex.CursorKind.<name> if available in this libclang binding, else None.
    This avoids crashes across different clang/python bindings.
    """
    return getattr(cindex.CursorKind, name, None)


# CursorKind compatibility (varies by libclang version / python bindings)
CK_CXX_TRY = _ck("CXX_TRY_STMT") or _ck("TRY_STMT")
CK_CXX_CATCH = _ck("CXX_CATCH_STMT")


class SemanticRole(Enum):
    INIT = "init"
    VALIDATION = "validation"
    LOOP = "loop"
    COMPUTE = "compute"
    IO = "io"
    ERROR = "error"
    FINALIZE = "finalize"


def infer_role(label: str) -> SemanticRole:
    """
    Infer a semantic role from an already-sanitized label.
    Heuristic only, not codebase-specific (no hardcoding to examples).
    """
    l = (label or "").lower()

    if any(w in l for w in ("init", "initialize", "create", "setup", "prepare", "allocate")):
        return SemanticRole.INIT
    if any(w in l for w in ("check", "validate", "verify", "ensure", "guard")):
        return SemanticRole.VALIDATION
    if any(w in l for w in ("loop", "iterate", "repeat", "traverse", "scan")):
        return SemanticRole.LOOP
    if any(w in l for w in ("print", "output", "log", "write", "read", "emit")):
        return SemanticRole.IO
    if any(w in l for w in ("error", "fail", "exception", "catch", "throw")):
        return SemanticRole.ERROR
    if any(w in l for w in ("cleanup", "finalize", "return", "finish", "close")):
        return SemanticRole.FINALIZE
    return SemanticRole.COMPUTE


def is_cpp_file(path: str) -> bool:
    return path.endswith(SUPPORTED_EXT)


def get_module_name(file_path: str, root_dir: str) -> str:
    rel = os.path.relpath(file_path, root_dir)
    no_ext = os.path.splitext(rel)[0]
    return ".".join(no_ext.split(os.sep))


def node_uid(cursor) -> str:
    loc = cursor.location
    return f"{cursor.spelling}:{loc.file.name}:{loc.line}"


def clean_unicode_chars(text: str) -> str:
    """Keep printable ASCII + newlines/tabs only."""
    if not text:
        return ""
    ascii_text = text.encode("ascii", "ignore").decode("ascii")
    ascii_text = re.sub(r"[^\x20-\x7E\n\r\t]", "", ascii_text)
    return ascii_text


def clamp_label(s: str) -> str:
    s = clean_unicode_chars(s or "")
    s = re.sub(r"\s+", " ", s).strip()
    if len(s) > MAX_LABEL_CHARS:
        s = s[: MAX_LABEL_CHARS - 3].rstrip() + "..."
    return s


def clean_label_text(label: str) -> str:
    """
    Mermaid-safe, readable label:
    - ASCII
    - no operators or code punctuation
    - no parentheses/braces/brackets/;:
    """
    label = clean_unicode_chars(label or "")

    # Replace operators with words
    label = (
        label.replace("!=", " not equal ")
        .replace("==", " equal ")
        .replace(">=", " greater or equal ")
        .replace("<=", " less or equal ")
        .replace("&&", " and ")
        .replace("||", " or ")
        .replace(">", " greater ")
        .replace("<", " less ")
    )

    # Replace function-call syntax foo(...) -> call foo
    label = re.sub(r"\b([A-Za-z_][A-Za-z0-9_]*)\s*\([^)]*\)", r"call \1", label)

    # Remove punctuation/brackets that can break Mermaid parsing
    label = re.sub(r"[{}()\[\];:]", " ", label)
    label = label.replace("?", " ")

    label = re.sub(r"\s+", " ", label).strip()
    return clamp_label(label) or "Process block"


def extract_source_lines(file_lines: list[str], start_line: int, end_line: int) -> list[str]:
    start_line = max(1, start_line)
    end_line = max(start_line, end_line)
    return [l.rstrip("\n") for l in file_lines[start_line - 1 : min(len(file_lines), end_line)]]


def cursor_text(cursor, file_lines: list[str]) -> str:
    if not cursor or not getattr(cursor, "extent", None):
        return ""
    return "\n".join(extract_source_lines(file_lines, cursor.extent.start.line, cursor.extent.end.line)).strip()


def extract_function_calls_from_text(text: str) -> list[str]:
    """Deterministic call extraction (for summary prompt only)."""
    pattern = r"\b([A-Za-z_][A-Za-z0-9_]*)\s*\("
    matches = re.findall(pattern, text or "")
    keywords = {
        "if",
        "while",
        "for",
        "switch",
        "return",
        "new",
        "delete",
        "sizeof",
        "static_cast",
        "dynamic_cast",
        "const_cast",
        "reinterpret_cast",
        "catch",
        "throw",
        "try",
    }
    out: list[str] = []
    seen = set()
    for m in matches:
        if m in keywords:
            continue
        if m not in seen:
            out.append(m)
            seen.add(m)
    return out


def summarize_block_with_llm(block_text: str) -> str:
    """
    Summarize a block into a short phrase. Chunk deterministically if too large.
    The LLM never sees the whole function, only small blocks.
    """
    block_text = clean_unicode_chars(block_text or "").strip()
    if not block_text:
        return "Process block"

    lines = block_text.splitlines()
    if len(lines) > MAX_BLOCK_LINES:
        parts: list[str] = []
        for i in range(0, len(lines), MAX_BLOCK_LINES):
            chunk = "\n".join(lines[i : i + MAX_BLOCK_LINES]).strip()
            parts.append(_summarize_once(chunk))
        return clamp_label(" / ".join(parts)) or "Process block"

    return _summarize_once(block_text)


def _summarize_once(block_text: str) -> str:
    calls = extract_function_calls_from_text(block_text)
    calls_str = ", ".join(calls[:10]) if calls else "none"

    prompt = (
        "You summarize a C++ code block for a flowchart node.\n"
        "Goal: describe the intent/logic, not the code phrasing.\n"
        "Strict rules:\n"
        "- Output ONE short phrase (3 to 8 words).\n"
        "- Do NOT invent behavior outside this block.\n"
        "- Avoid trivial variable names and numeric literals unless essential.\n"
        "- If the block calls functions, mention their names exactly.\n"
        "- No operators (==, !=, >, <) and no parentheses.\n"
        "- ASCII only.\n"
        f"Detected calls: {calls_str}\n"
        "Block:\n"
        "{block}\n"
        "Phrase:"
    )
    query = prompt.format(block=block_text)

    for _ in range(MAX_SUMMARY_RETRIES):
        try:
            resp = llm.invoke([HumanMessage(query)])
            phrase = clean_label_text(resp.content)
            if phrase:
                return phrase
        except Exception:
            pass
    return "Process block"


@dataclass
class Graph:
    nodes: dict[str, tuple[str, str]]  # id -> (shape, label) where shape in {"process","decision"}
    edges: list[tuple[str, str, str]]  # (src, dst, label)


class FlowBuilder:
    """
    Deterministic flow builder from AST statements.
    Basic blocks = grouped consecutive non-control statements.
    """

    def __init__(self, file_lines: list[str]):
        self.file_lines = file_lines
        self.nodes: dict[str, tuple[str, str]] = {}
        self.edges: list[tuple[str, str, str]] = []
        self._next_id = 1
        self.loop_stack: list[tuple[str, str]] = []  # (continue_target, break_target)
        self.switch_stack: list[str] = []  # break_target
        self.node_meta: dict[str, dict] = {}  # node_id -> metadata (role, original_text, etc.)

    def new_node(self, shape: str, label: str) -> str:
        nid = f"n{self._next_id}"
        self._next_id += 1
        clean = clean_label_text(label)
        self.nodes[nid] = (shape, clean)
        self.node_meta[nid] = {
            "role": infer_role(clean),
            "label": clean,
            "shape": shape,
        }
        return nid

    def add_edge(self, src: str, dst: str, label: str = ""):
        if not src or not dst:
            return
        self.edges.append((src, dst, clean_label_text(label) if label else ""))

    def build_function(self, fn_cursor) -> Graph:
        body = None
        for ch in fn_cursor.get_children():
            if ch.kind == cindex.CursorKind.COMPOUND_STMT:
                body = ch
                break

        if body is None:
            n = self.new_node("process", "No implementation")
            self.add_edge("Start", n)
            self.add_edge(n, "End")
            return Graph(self.nodes, self.edges)

        entry, exits = self.build_compound(body)
        self.add_edge("Start", entry)
        for ex in exits:
            self.add_edge(ex, "End")
        return Graph(self.nodes, self.edges)

    def build_stmt(self, cursor) -> tuple[str, list[str]]:
        k = cursor.kind

        if k == cindex.CursorKind.RETURN_STMT:
            n = self.new_node("process", "Return from function")
            return n, []

        if k == cindex.CursorKind.BREAK_STMT:
            n = self.new_node("process", "Break")
            if self.switch_stack:
                self.add_edge(n, self.switch_stack[-1])
            elif self.loop_stack:
                self.add_edge(n, self.loop_stack[-1][1])
            return n, []

        if k == cindex.CursorKind.CONTINUE_STMT:
            n = self.new_node("process", "Continue")
            if self.loop_stack:
                self.add_edge(n, self.loop_stack[-1][0])
            return n, []

        if k == cindex.CursorKind.IF_STMT:
            return self._build_if(cursor)

        if k in (cindex.CursorKind.FOR_STMT, cindex.CursorKind.WHILE_STMT, cindex.CursorKind.DO_STMT):
            return self._build_loop(cursor)

        if k == cindex.CursorKind.SWITCH_STMT:
            return self._build_switch(cursor)

        if CK_CXX_TRY is not None and k == CK_CXX_TRY:
            return self._build_try(cursor)

        return self.build_compound(cursor)

    def build_compound(self, cursor) -> tuple[str, list[str]]:
        """
        If cursor is a COMPOUND_STMT: group sequential non-control statements into one block.
        Otherwise: treat cursor as a single-statement block (still summarized).
        """
        if cursor is None:
            n = self.new_node("process", "No operation")
            return n, [n]

        if cursor.kind != cindex.CursorKind.COMPOUND_STMT:
            text = cursor_text(cursor, self.file_lines)
            n = self.new_node("process", summarize_block_with_llm(text))
            return n, [n]

        children = list(cursor.get_children())
        entry: Optional[str] = None
        curr_exits: list[str] = []
        pending: list = []

        def flush() -> None:
            nonlocal entry, curr_exits, pending
            if not pending:
                return

            # Split long straight-line code into smaller segments deterministically.
            segments: list[list] = []
            current: list = []
            current_lines = 0

            for stmt in pending:
                txt = cursor_text(stmt, self.file_lines)
                line_count = max(1, len(txt.splitlines())) if txt else 1

                if (
                    current
                    and (
                        len(current) >= PENDING_SEGMENT_MAX_STMTS
                        or (current_lines + line_count) > PENDING_SEGMENT_MAX_LINES
                    )
                ):
                    segments.append(current)
                    current = []
                    current_lines = 0

                current.append(stmt)
                current_lines += line_count

            if current:
                segments.append(current)

            for seg in segments:
                text = "\n".join(t for t in (cursor_text(s, self.file_lines) for s in seg) if t)
                label = summarize_block_with_llm(text)
                n = self.new_node("process", label)
                if entry is None:
                    entry = n
                if curr_exits:
                    for ex in curr_exits:
                        self.add_edge(ex, n)
                curr_exits = [n]

            pending = []

        CONTROL_KINDS = {
            cindex.CursorKind.IF_STMT,
            cindex.CursorKind.FOR_STMT,
            cindex.CursorKind.WHILE_STMT,
            cindex.CursorKind.DO_STMT,
            cindex.CursorKind.SWITCH_STMT,
            CK_CXX_TRY,
            cindex.CursorKind.RETURN_STMT,
            cindex.CursorKind.BREAK_STMT,
            cindex.CursorKind.CONTINUE_STMT,
        }
        # Remove Nones (when a kind doesn't exist in this binding)
        CONTROL_KINDS = {k for k in CONTROL_KINDS if k is not None}

        for child in children:
            if child.kind in CONTROL_KINDS:
                flush()
                s_entry, s_exits = self.build_stmt(child)
                if entry is None:
                    entry = s_entry
                if curr_exits:
                    for ex in curr_exits:
                        self.add_edge(ex, s_entry)
                curr_exits = s_exits
            else:
                pending.append(child)

        flush()

        if entry is None:
            n = self.new_node("process", "No operation")
            return n, [n]
        return entry, curr_exits


@dataclass
class Region:
    id: str
    nodes: list[str]           # node ids in detailed graph
    shape: str                 # "process" or "decision"
    role: SemanticRole
    label: str = ""


def build_regions(graph: Graph, node_meta: dict[str, dict]) -> list[Region]:
    """
    Merge linear chains of PROCESS nodes with same role.
    Deterministic: only merges when indegree==1 and outdegree==1 between nodes.
    """
    indeg = defaultdict(int)
    out = defaultdict(list)
    for src, dst, _ in graph.edges:
        if src in ("Start", "End") or dst in ("Start", "End"):
            continue
        indeg[dst] += 1
        out[src].append(dst)

    visited = set()
    regions: list[Region] = []
    rid = 1

    for nid, (shape, label) in graph.nodes.items():
        if nid in visited:
            continue

        meta = node_meta.get(nid, {})
        role = meta.get("role", infer_role(label))

        # decisions are never merged (single node region)
        if shape == "decision":
            regions.append(Region(id=f"R{rid}", nodes=[nid], shape=shape, role=SemanticRole.VALIDATION, label=label))
            visited.add(nid)
            rid += 1
            continue

        # process node: attempt to merge forward in a linear chain
        chain = [nid]
        visited.add(nid)
        curr = nid

        while len(chain) < MAX_REGION_NODES:
            nxts = out.get(curr, [])
            if len(nxts) != 1:
                break
            nxt = nxts[0]
            if nxt in visited:
                break
            nxt_shape, nxt_label = graph.nodes.get(nxt, ("", ""))
            if nxt_shape != "process":
                break
            nxt_role = node_meta.get(nxt, {}).get("role", infer_role(nxt_label))
            if nxt_role != role:
                break
            if indeg.get(nxt, 0) != 1:
                break
            chain.append(nxt)
            visited.add(nxt)
            curr = nxt

        regions.append(Region(id=f"R{rid}", nodes=chain, shape="process", role=role))
        rid += 1

    return regions


def name_region_with_llm(region: Region, graph: Graph) -> str:
    """
    Name a merged region using ONLY existing block labels (LLM never sees raw code here).
    This keeps hallucination risk low even for huge functions.
    """
    labels = []
    for n in region.nodes:
        _, lbl = graph.nodes.get(n, ("process", ""))
        if lbl:
            labels.append(lbl)
    if not labels:
        return "Process block"
    if len(labels) == 1:
        return labels[0]

    prompt = (
        "You name a flowchart block from existing labels.\n"
        "Rules:\n"
        f"- {REGION_NAME_WORDS_MIN} to {REGION_NAME_WORDS_MAX} words.\n"
        "- Do NOT invent new behavior.\n"
        "- Use ONLY the provided labels.\n"
        "- No punctuation.\n\n"
        "Labels:\n"
        + "\n".join(f"- {l}" for l in labels)
        + "\n\nName:"
    )
    try:
        resp = llm.invoke([HumanMessage(prompt)])
        return clean_label_text(resp.content) or labels[0]
    except Exception:
        return labels[0]


def render_abstract_mermaid(graph: Graph, regions: list[Region]) -> str:
    """
    Render region-level flowchart (gist view).
    Keeps decision regions as diamonds and process regions as rectangles.
    """
    lines = ["flowchart TD", "Start((Start))"]

    node_to_region = {}
    for r in regions:
        for n in r.nodes:
            node_to_region[n] = r.id

    # region nodes
    for r in regions:
        lbl = clean_label_text(r.label or r.id)
        if r.shape == "decision":
            lines.append(f"{r.id}{{{{{lbl}}}}}")
        else:
            lines.append(f"{r.id}[{lbl}]")
    lines.append("End((End))")

    # region edges
    added = set()
    start_targets = set()
    end_sources = set()

    for src, dst, elbl in graph.edges:
        if src == "Start":
            rs = node_to_region.get(dst)
            if rs:
                start_targets.add(rs)
            continue
        if dst == "End":
            rs = node_to_region.get(src)
            if rs:
                end_sources.add(rs)
            continue
        if src in ("End",) or dst in ("Start",):
            continue
        rs = node_to_region.get(src)
        rd = node_to_region.get(dst)
        if not rs or not rd or rs == rd:
            continue
        key = (rs, rd, elbl.strip() if elbl else "")
        # normalize: if multiple different labels for same rs->rd, drop label
        key_nolbl = (rs, rd)
        if key_nolbl in added:
            continue
        if elbl:
            lines.append(f\"{rs} --> |{clean_label_text(elbl)}| {rd}\")
        else:
            lines.append(f\"{rs} --> {rd}\")
        added.add(key_nolbl)

    # Connect Start and End
    for t in sorted(start_targets):
        lines.append(f"Start --> {t}")
    for s in sorted(end_sources):
        lines.append(f"{s} --> End")

    return "\n".join(lines) + "\n"

    def _build_if(self, cursor) -> tuple[str, list[str]]:
        children = list(cursor.get_children())
        cond = children[0] if children else None
        then_stmt = children[1] if len(children) > 1 else None
        else_stmt = children[2] if len(children) > 2 else None

        cond_label = clean_label_text(cursor_text(cond, self.file_lines) or "condition")
        d = self.new_node("decision", f"Check {cond_label}")

        t_entry, t_exits = self.build_compound(then_stmt)
        self.add_edge(d, t_entry, "true")

        if else_stmt:
            f_entry, f_exits = self.build_compound(else_stmt)
            self.add_edge(d, f_entry, "false")
            return d, (t_exits + f_exits)

        # no else: false falls through by returning decision node as an exit too
        return d, (t_exits + [d])

    def _build_loop(self, cursor) -> tuple[str, list[str]]:
        k = cursor.kind
        children = list(cursor.get_children())

        cond = None
        body = None
        if k == cindex.CursorKind.WHILE_STMT:
            cond = children[0] if len(children) > 0 else None
            body = children[1] if len(children) > 1 else None
        elif k == cindex.CursorKind.DO_STMT:
            body = children[0] if len(children) > 0 else None
            cond = children[1] if len(children) > 1 else None
        else:  # FOR
            cond = children[1] if len(children) > 1 else None
            body = children[-1] if children else None

        cond_label = clean_label_text(cursor_text(cond, self.file_lines) or "loop condition")
        check = self.new_node("decision", f"Check {cond_label}")
        after = self.new_node("process", "After loop")

        self.loop_stack.append((check, after))
        b_entry, b_exits = self.build_compound(body)
        self.loop_stack.pop()

        if k == cindex.CursorKind.DO_STMT:
            entry = b_entry
            for ex in b_exits:
                self.add_edge(ex, check)
            self.add_edge(check, b_entry, "true")
            self.add_edge(check, after, "false")
            return entry, [after]

        self.add_edge(check, b_entry, "true")
        self.add_edge(check, after, "false")
        for ex in b_exits:
            self.add_edge(ex, check)
        return check, [after]

    def _build_switch(self, cursor) -> tuple[str, list[str]]:
        children = list(cursor.get_children())
        expr = children[0] if children else None
        body = children[1] if len(children) > 1 else None

        expr_label = clean_label_text(cursor_text(expr, self.file_lines) or "expression")
        d = self.new_node("decision", f"Switch on {expr_label}")
        after = self.new_node("process", "After switch")

        self.switch_stack.append(after)

        cases = []
        default_case = None
        if body:
            for ch in body.get_children():
                if ch.kind == cindex.CursorKind.CASE_STMT:
                    cases.append(ch)
                elif ch.kind == cindex.CursorKind.DEFAULT_STMT:
                    default_case = ch

        built: list[tuple[str, str, list[str]]] = []
        for c in cases:
            raw = cursor_text(c, self.file_lines)
            case_label = clean_label_text(raw.split(":")[0] if ":" in raw else "case")
            c_children = list(c.get_children())
            c_body = c_children[-1] if c_children else None
            entry, exits = self.build_compound(c_body)
            built.append((case_label, entry, exits))

        if default_case:
            d_children = list(default_case.get_children())
            d_body = d_children[-1] if d_children else None
            entry, exits = self.build_compound(d_body)
            built.append(("default", entry, exits))

        for lbl, entry, _ in built:
            self.add_edge(d, entry, lbl)

        # Best-effort fallthrough: connect exits to next case
        for i in range(len(built) - 1):
            next_entry = built[i + 1][1]
            for ex in built[i][2]:
                self.add_edge(ex, next_entry, "fallthrough")

        if built:
            for ex in built[-1][2]:
                self.add_edge(ex, after)
        else:
            self.add_edge(d, after, "default")

        self.switch_stack.pop()
        return d, [after]

    def _build_try(self, cursor) -> tuple[str, list[str]]:
        children = list(cursor.get_children())
        try_block = children[0] if children else None
        catches = children[1:] if len(children) > 1 else []

        # Some bindings expose catch blocks as CXX_CATCH_STMT nodes; filter if possible.
        if CK_CXX_CATCH is not None:
            catches = [c for c in catches if c.kind == CK_CXX_CATCH] or catches

        decision = self.new_node("decision", "Exception occurs")
        after = self.new_node("process", "After try catch")

        t_entry, t_exits = self.build_compound(try_block)
        self.add_edge(decision, t_entry, "no")
        for ex in t_exits:
            self.add_edge(ex, after)

        if catches:
            catch_text = "\n".join(t for t in (cursor_text(c, self.file_lines) for c in catches) if t)
            catch_label = summarize_block_with_llm(catch_text) if catch_text else "Handle exception"
            c_node = self.new_node("process", catch_label)
            self.add_edge(decision, c_node, "yes")
            self.add_edge(c_node, after)
        else:
            self.add_edge(decision, after, "yes")

        return decision, [after]


def render_mermaid(graph: Graph) -> str:
    lines = ["flowchart TD", "Start((Start))"]

    # Explicit node definitions
    for nid, (shape, label) in graph.nodes.items():
        lbl = clean_label_text(label)
        if shape == "decision":
            lines.append(f"{nid}{{{{{lbl}}}}}")
        else:
            lines.append(f"{nid}[{lbl}]")

    lines.append("End((End))")

    # One edge per line
    for src, dst, lbl in graph.edges:
        if lbl:
            lines.append(f"{src} --> |{clean_label_text(lbl)}| {dst}")
        else:
            lines.append(f"{src} --> {dst}")

    return "\n".join(lines) + "\n"


def validate_mermaid(mermaid: str) -> tuple[bool, Optional[str]]:
    if not mermaid or not mermaid.strip():
        return False, "Empty flowchart"
    if "flowchart" not in mermaid.lower():
        return False, "Missing flowchart declaration"
    if "Start((Start))" not in mermaid:
        return False, "Missing Start node"
    if "End((End))" not in mermaid:
        return False, "Missing End node"
    if "&#" in mermaid:
        return False, "HTML entities detected"
    for line in mermaid.splitlines():
        if line.count("-->") > 1:
            return False, "Multiple edges in one line"
    return True, None


def generate_flowchart_for_function(fn_cursor, file_lines: list[str]) -> tuple[str, Optional[str], Optional[str]]:
    """
    Returns abstract (gist) mermaid as primary, plus detailed mermaid via extra key in JSON.
    """
    builder = FlowBuilder(file_lines)
    graph = builder.build_function(fn_cursor)
    detailed = render_mermaid(graph)
    ok, err = validate_mermaid(detailed)
    if not ok:
        return detailed, None, f"Detailed validation failed: {err}"

    # Build/Name regions => abstract
    regions = build_regions(graph, builder.node_meta)
    for r in regions:
        r.label = name_region_with_llm(r, graph)
    abstract = render_abstract_mermaid(graph, regions)
    ok2, err2 = validate_mermaid(abstract)
    if not ok2:
        # fall back to detailed if abstract failed (still deterministic)
        abstract = detailed

    # Image conversion: generate abstract image (and optionally detailed as _detailed)
    img_path = None
    feedback = None
    currdir = os.getcwd()
    try:
        os.chdir(mermaid_path)
        subprocess.check_output(
            ["node", "index.js", abstract, f"{fn_cursor.spelling}.png"],
            stderr=subprocess.STDOUT,
            timeout=30,
        )
        img_path = os.path.join(mermaid_path, f"{fn_cursor.spelling}.png")
    except Exception as e:
        feedback = f"Mermaid image generation failed: {str(e)[:200]}"
    finally:
        os.chdir(currdir)

    # Store detailed in a temp attribute on cursor for extract_node_info to pick up
    setattr(fn_cursor, "_agent9_flowchart_detailed", detailed)
    return abstract, img_path, feedback


def generate_function_description(function_lines: list[str]) -> str:
    prompt = (
        "You are a C++ code documentation expert.\n"
        "Provide a concise 2-3 sentence description.\n"
        "Do not invent anything.\n\n"
        "Function:\n"
        "{function}\n"
        "Description:"
    )
    query = prompt.format(function="\n".join(function_lines[:120]))
    try:
        resp = llm.invoke([HumanMessage(query)])
        return clean_unicode_chars(resp.content).strip()
    except Exception:
        return "Description generation failed"


def extract_node_info(fn_cursor, file_path: str, module_name: str) -> Optional[dict]:
    extent = fn_cursor.extent
    try:
        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
            file_lines = f.readlines()

        function_lines = extract_source_lines(file_lines, extent.start.line, extent.end.line)
        function_lines = [l.rstrip() for l in function_lines if l.strip()]
        if not function_lines:
            return None

        mermaid, img_path, feedback = generate_flowchart_for_function(fn_cursor, file_lines)
        mermaid_detailed = getattr(fn_cursor, "_agent9_flowchart_detailed", None)

        return {
            "uid": node_uid(fn_cursor),
            "name": fn_cursor.spelling,
            "line_start": extent.start.line,
            "column_start": extent.start.column,
            "line_end": extent.end.line,
            "column_end": extent.end.column,
            "file_name": file_path,
            "module_name": module_name,
            "description": generate_function_description(function_lines),
            "flowchart": mermaid,
            "flowchart_detailed": mermaid_detailed,
            "feedback": feedback,
            "img": img_path,
            "callees": [],
            "callers": [],
        }
    except Exception as e:
        print(f"[WARN] extract_node_info failed for {fn_cursor.spelling}: {e}")
        return None


def visit(cursor, file_path: str, module_name: str, nodes: dict, call_edges, current_fn_uid: Optional[str], visited=None):
    if visited is None:
        visited = set()

    if cursor.location.file and cursor.location.file.name != file_path:
        return

    fqn = f"{module_name}::{file_path}::{cursor.spelling}"
    if fqn in visited:
        return

    if cursor.is_definition() and cursor.kind in (
        cindex.CursorKind.FUNCTION_DECL,
        cindex.CursorKind.CXX_METHOD,
        cindex.CursorKind.CONSTRUCTOR,
        cindex.CursorKind.DESTRUCTOR,
    ):
        visited.add(fqn)
        uid = node_uid(cursor)
        if uid not in nodes and cursor.spelling:
            info = extract_node_info(cursor, file_path, module_name)
            if info:
                nodes[uid] = info
                current_fn_uid = uid

    if cursor.kind == cindex.CursorKind.CALL_EXPR and current_fn_uid:
        ref = cursor.referenced
        if ref and ref.spelling and ref.location.file:
            callee_uid = node_uid(ref)
            call_edges[current_fn_uid].add(callee_uid)

    for child in cursor.get_children():
        visit(child, file_path, module_name, nodes, call_edges, current_fn_uid, visited)


def generate_word_document(data: list[dict], doc_name: str):
    doc = Document()
    for index, item in enumerate(data, start=1):
        doc.add_heading(f"1.1.{index} {item['name']}", level=1)
        table = doc.add_table(rows=2, cols=2, style="Table Grid")
        table.rows[0].cells[0].text = "Requirement ID"
        table.rows[0].cells[1].text = f"SAVV8-SwU-{index}"
        table.rows[1].cells[0].text = "Flowchart"

        if item.get("img") and os.path.exists(item["img"]):
            table.rows[1].cells[1].add_paragraph().add_run().add_picture(item["img"], width=Inches(6.0))
        else:
            table.rows[1].cells[1].text = item.get("feedback") or "Flowchart image not available"

    os.makedirs(os.path.dirname(doc_name), exist_ok=True)
    doc.save(doc_name)


def parse_file(index, file_path: str, root_dir: str, compile_args: list[str], out_nodes: dict, out_edges):
    module_name = get_module_name(file_path, root_dir)
    tu = index.parse(
        file_path,
        args=compile_args,
        options=cindex.TranslationUnit.PARSE_DETAILED_PROCESSING_RECORD,
    )

    my_nodes: dict = {}
    my_edges = defaultdict(set)
    visit(tu.cursor, file_path, module_name, my_nodes, my_edges, None)

    if not my_nodes:
        return

    base = os.path.splitext(os.path.basename(file_path))[0]
    meta_name = base
    # handle duplicate basenames across directories
    if meta_name in out_nodes:
        meta_name = f"{meta_name}_{len(out_nodes)}"

    json_path = os.path.join(out_dir, f"{meta_name}.json")
    docx_path = os.path.join(out_dir, f"{base}.docx")

    generate_word_document(list(my_nodes.values()), docx_path)
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(list(my_nodes.values()), f, indent=2, ensure_ascii=False)

    out_nodes.update(my_nodes)
    out_edges.update(my_edges)


def parse_codebase(root_dir: str, compile_args: Optional[list[str]] = None) -> list[dict]:
    compile_args = compile_args or ["-std=c++17"]
    index = cindex.Index.create()
    nodes: dict = {}
    call_edges = defaultdict(set)

    for root, _, files in os.walk(root_dir):
        for f in files:
            if is_cpp_file(f):
                path = os.path.join(root, f)
                try:
                    parse_file(index, path, root_dir, compile_args, nodes, call_edges)
                except Exception as e:
                    print(f"[WARN] Failed to parse {path}: {e}")

    return list(nodes.values())


def main():
    parser = argparse.ArgumentParser(description="Generate AST-driven flowcharts for C++ functions")
    parser.add_argument("path", help="C++ codebase root directory")
    parser.add_argument("--std", default="c++17", help="C++ standard, e.g. c++17, c++20")
    parser.add_argument("--libclang", help="Path to libclang shared library")
    args = parser.parse_args()

    if args.libclang:
        cindex.Config.set_library_file(args.libclang)

    os.makedirs(out_dir, exist_ok=True)
    parse_codebase(args.path, compile_args=[f"-std={args.std}"])
    print("Done.")


if __name__ == "__main__":
    main()

