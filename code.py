"""
Agent9 - C++ function flowchart generator (AST-driven, low-hallucination)

Major goals (from requirements):
- Work on any C/C++ project: use libclang AST to parse.
- Generate a JSON list per parsed file with: name, location, description, mermaid flowchart, image path.
- Flowchart must be logically correct (control flow), valid Mermaid, and include function calls as black boxes.
- Do NOT go inside callees.
- Use open-source LLM via Ollama (ChatOllama).

Key approach to reduce hallucinations on large functions (300-600+ lines):
- AST deterministically defines control-flow (if/loop/switch/try/return/break/continue).
- LLM is used ONLY to summarize *small* basic blocks (<= MAX_BLOCK_LINES lines) into short labels.
- Mermaid is composed by this code (not generated by LLM).

NEW: Semantic grouping improvements:
- Group related statements that achieve "one conceptual thing"
- Labels describe WHAT is achieved, not HOW (code-in-text)
- Balance between over-splitting and over-collapsing
"""

from __future__ import annotations

import argparse
import json
import os
import re
import subprocess
from collections import defaultdict
from dataclasses import dataclass
from typing import Optional
from enum import Enum

from clang import cindex
from docx import Document
from docx.shared import Inches
from langchain.messages import HumanMessage
from langchain_ollama import ChatOllama


# OPTIONAL: Set explicitly if needed
# cindex.Config.set_library_file("/usr/lib/llvm-18/lib/libclang.so")

SUPPORTED_EXT = (".c", ".cpp", ".cc", ".cxx")

# Paths (update for your environment)
mermaid_path = "/home/workspace/mermaid_converter"
out_dir = "/home/workspace/adk/gemma-code/orchestrator/docs"

# LLM (open-source) via Ollama
llm = ChatOllama(model="gpt-oss", temperature=0.2, top_k=10, top_p=0.9)

# Chunking/safety limits
MAX_BLOCK_LINES = 80        # max lines per LLM block summary
MAX_LABEL_CHARS = 80        # max label length in Mermaid
MAX_SUMMARY_RETRIES = 3     # per block summary

# NEW: Semantic grouping parameters
MAX_REGION_NODES = 6        # max CFG nodes to merge into one semantic region
MAX_REGION_LINES = 30       # max source lines in a merged region (prevent over-collapsing)
MIN_REGION_LINES = 3        # min lines to consider merging

# NEW: Split long straight-line code into segments to avoid a single giant box
PENDING_SEGMENT_MAX_LINES = 25
PENDING_SEGMENT_MAX_STMTS = 10

KEYWORD_TOKENS = {
    "if",
    "for",
    "while",
    "switch",
    "return",
    "new",
    "delete",
    "sizeof",
    "static_cast",
    "dynamic_cast",
    "const_cast",
    "reinterpret_cast",
}


class SemanticRole(Enum):
    """Semantic role classification for code blocks."""
    INIT        = "init"        # Variable declarations, allocations, setup
    VALIDATION  = "validation"  # Checks, guards, assertions
    LOOP        = "loop"        # Iteration logic
    COMPUTE     = "compute"     # Calculations, data processing (default)
    IO          = "io"          # Input/output, logging, printing
    ERROR       = "error"       # Error handling, exceptions
    FINALIZE    = "finalize"    # Returns, cleanup, teardown
    CALL        = "call"        # Function calls (external behavior)


@dataclass
class Region:
    """A semantic region (merged CFG nodes)."""
    id: str
    nodes: list[str]
    role: SemanticRole
    shape: str
    entry: str
    exits: list[str]
    label: str = ""
    line_count: int = 0  # NEW: track source line count


def _ck(name: str):
    """
    Return cindex.CursorKind.<name> if available in this libclang binding, else None.
    This avoids crashes across different clang/python bindings.
    """
    return getattr(cindex.CursorKind, name, None)


# CursorKind compatibility (varies by libclang version / python bindings)
CK_CXX_TRY = _ck("CXX_TRY_STMT") or _ck("TRY_STMT")
CK_CXX_CATCH = _ck("CXX_CATCH_STMT")


def is_cpp_file(path: str) -> bool:
    return path.endswith(SUPPORTED_EXT)


def get_module_name(file_path: str, root_dir: str) -> str:
    rel = os.path.relpath(file_path, root_dir)
    no_ext = os.path.splitext(rel)[0]
    return ".".join(no_ext.split(os.sep))


def node_uid(cursor) -> str:
    loc = cursor.location
    return f"{cursor.spelling}:{loc.file.name}:{loc.line}"


def clean_unicode_chars(text: str) -> str:
    """Keep printable ASCII + newlines/tabs only."""
    if not text:
        return ""
    ascii_text = text.encode("ascii", "ignore").decode("ascii")
    ascii_text = re.sub(r"[^\x20-\x7E\n\r\t]", "", ascii_text)
    return ascii_text


def clamp_label(s: str) -> str:
    s = clean_unicode_chars(s or "")
    s = re.sub(r"\s+", " ", s).strip()
    if len(s) > MAX_LABEL_CHARS:
        s = s[: MAX_LABEL_CHARS - 3].rstrip() + "..."
    return s


def _replace_function_calls(text: str, for_condition: bool) -> str:
    """
    Replace function calls in a Mermaid-safe way.
    - For conditions: keep function name without "call" (avoid "call if")
    - For non-conditions: use "call <name>" to show black-box calls
    """
    if not text:
        return text

    def repl(match: re.Match) -> str:
        name = match.group(1)
        if name in KEYWORD_TOKENS:
            return name
        return name if for_condition else f"call {name}"

    # Method calls: obj.method(...) or ptr->method(...)
    def repl_method(match: re.Match) -> str:
        obj = match.group(1)
        method = match.group(2)
        if method in KEYWORD_TOKENS:
            return f"{obj} {method}"
        return f"{obj} {method}" if for_condition else f"call {method}"

    text = re.sub(r"\b([A-Za-z_][A-Za-z0-9_:]*)\s*(?:\.|->)\s*([A-Za-z_][A-Za-z0-9_]*)\s*\([^)]*\)", repl_method, text)
    text = re.sub(r"\b([A-Za-z_][A-Za-z0-9_]*)\s*\([^)]*\)", repl, text)
    return text


def clean_label_text(label: str, for_condition: bool = False) -> str:
    """
    Mermaid-safe, readable label:
    - ASCII
    - no operators or code punctuation
    - no parentheses/braces/brackets/;:
    """
    label = clean_unicode_chars(label or "")

    # Replace operators with words
    label = (
        label.replace("!=", " not equal ")
        .replace("==", " equal ")
        .replace(">=", " greater or equal ")
        .replace("<=", " less or equal ")
        .replace("&&", " and ")
        .replace("||", " or ")
        .replace(">", " greater ")
        .replace("<", " less ")
    )

    # Replace function-call syntax
    label = _replace_function_calls(label, for_condition=for_condition)

    # Remove punctuation/brackets that can break Mermaid parsing
    label = re.sub(r"[{}()\[\];:]", " ", label)
    label = label.replace("?", " ")

    label = re.sub(r"\s+", " ", label).strip()
    return clamp_label(label) or "Process block"


def clean_condition_text(label: str) -> str:
    """
    Clean condition expressions for decision nodes.
    Removes leading control keywords and avoids "call <keyword>" artifacts.
    """
    label = clean_unicode_chars(label or "")
    label = re.sub(r"^\s*(if|for|while|switch)\b", "", label, flags=re.IGNORECASE).strip()
    return clean_label_text(label, for_condition=True)


def _is_code_like(label: str) -> bool:
    """
    Heuristic: detect labels that still read like code/textual statements.
    """
    l = (label or "").lower()
    if re.search(r"\b\d+\b", l):
        return True
    if re.search(r"\b[a-z]\b", l):
        return True
    if any(w in l for w in ("initialize", "assign", "variable", "increment", "decrement")):
        return True
    return False


def _rewrite_label_semantic(label: str) -> str:
    """
    Rephrase a label into a semantic purpose (short phrase).
    Uses LLM but does not provide raw code (only the label).
    """
    prompt = (
        "Rewrite this flowchart label to describe intent/purpose.\n"
        "Rules:\n"
        "- Output ONE short phrase (3 to 8 words)\n"
        "- Remove variable names, constants, and code-like phrasing\n"
        "- Focus on WHAT is achieved, not HOW\n"
        "- No punctuation, ASCII only\n\n"
        f"Label: {label}\n"
        "Semantic label:"
    )
    try:
        resp = llm.invoke([HumanMessage(prompt)])
        return clean_label_text(resp.content)
    except Exception:
        return label


def infer_role(label: str, code_text: str = "") -> SemanticRole:
    """
    Infer semantic role from label and optionally code text.
    
    NEW: Enhanced heuristics for better role detection.
    """
    l = (label or "").lower()
    c = (code_text or "").lower()

    # Check for function calls first
    if any(w in l for w in ("call", "invoke", "execute")):
        return SemanticRole.CALL

    # Initialization patterns
    if any(w in l for w in ("initialize", "init", "create", "setup", "prepare", "allocate", "declare")):
        return SemanticRole.INIT
    if re.search(r'\b(int|float|double|string|vector|map|auto)\s+\w+\s*=', c):
        return SemanticRole.INIT

    # Validation patterns
    if any(w in l for w in ("check", "validate", "verify", "ensure", "guard", "assert", "test")):
        return SemanticRole.VALIDATION

    # Loop patterns
    if any(w in l for w in ("loop", "iterate", "repeat", "traverse", "scan", "for each")):
        return SemanticRole.LOOP

    # I/O patterns
    if any(w in l for w in ("print", "output", "log", "cout", "cerr", "read", "write", "input", "display")):
        return SemanticRole.IO

    # Error handling patterns
    if any(w in l for w in ("error", "exception", "fail", "catch", "throw", "handle")):
        return SemanticRole.ERROR

    # Finalization patterns
    if any(w in l for w in ("return", "cleanup", "finalize", "close", "delete", "free", "exit")):
        return SemanticRole.FINALIZE

    # Default: compute
    return SemanticRole.COMPUTE


def extract_source_lines(file_lines: list[str], start_line: int, end_line: int) -> list[str]:
    start_line = max(1, start_line)
    end_line = max(start_line, end_line)
    return [l.rstrip("\n") for l in file_lines[start_line - 1 : min(len(file_lines), end_line)]]


def cursor_text(cursor, file_lines: list[str]) -> str:
    if not cursor or not getattr(cursor, "extent", None):
        return ""
    return "\n".join(extract_source_lines(file_lines, cursor.extent.start.line, cursor.extent.end.line)).strip()


def extract_function_calls_from_text(text: str) -> list[str]:
    """Deterministic call extraction (for summary prompt only)."""
    pattern = r"\b([A-Za-z_][A-Za-z0-9_]*)\s*\("
    matches = re.findall(pattern, text or "")
    keywords = {
        "if", "while", "for", "switch", "return", "new", "delete", "sizeof",
        "static_cast", "dynamic_cast", "const_cast", "reinterpret_cast",
        "catch", "throw", "try",
    }
    out: list[str] = []
    seen = set()
    for m in matches:
        if m in keywords:
            continue
        if m not in seen:
            out.append(m)
            seen.add(m)
    return out


def summarize_block_with_llm(block_text: str) -> str:
    """
    Summarize a block into a short phrase. Chunk deterministically if too large.
    The LLM never sees the whole function, only small blocks.
    """
    block_text = clean_unicode_chars(block_text or "").strip()
    if not block_text:
        return "Process block"

    lines = block_text.splitlines()
    if len(lines) > MAX_BLOCK_LINES:
        parts: list[str] = []
        for i in range(0, len(lines), MAX_BLOCK_LINES):
            chunk = "\n".join(lines[i : i + MAX_BLOCK_LINES]).strip()
            parts.append(_summarize_once(chunk))
        return clamp_label(" / ".join(parts)) or "Process block"

    return _summarize_once(block_text)


def _summarize_once(block_text: str) -> str:
    """
    NEW: Improved prompt for SEMANTIC/LOGICAL descriptions.
    
    Goal: Get "WHAT is achieved" not "code in text format".
    """
    calls = extract_function_calls_from_text(block_text)
    calls_str = ", ".join(calls[:10]) if calls else "none"

    # NEW PROMPT: Focus on semantic intent
    prompt = (
        "You are analyzing C++ code for a flowchart.\n"
        "Goal: Describe WHAT this code achieves (the intent/purpose), NOT the code itself.\n"
        "\n"
        "Rules:\n"
        "- Output ONE short phrase (3 to 8 words)\n"
        "- Focus on the GOAL/PURPOSE, not the implementation\n"
        "- Bad: 'Initialize variable a to 95' → Good: 'Setup test parameters'\n"
        "- Bad: 'Assign b to a times two' → Good: 'Compute derived values'\n"
        "- Bad: 'Sum elements of data' → Good: 'Accumulate total'\n"
        "- If calling functions, mention their purpose: 'call helper' → 'Apply transformation'\n"
        "- No operators (==, !=, >, <) and no parentheses\n"
        "- No variable names unless essential\n"
        "- ASCII only\n"
        "\n"
        f"Function calls detected: {calls_str}\n"
        "\n"
        "Code block:\n"
        "{block}\n"
        "\n"
        "Semantic description:"
    )
    query = prompt.format(block=block_text)

    for _ in range(MAX_SUMMARY_RETRIES):
        try:
            resp = llm.invoke([HumanMessage(query)])
            phrase = clean_label_text(resp.content)
            if phrase:
                return phrase
        except Exception:
            pass
    return "Process block"


@dataclass
class Graph:
    nodes: dict[str, dict]  # id -> {"shape": str, "label": str, "role": SemanticRole, "line_count": int}
    edges: list[tuple[str, str, str]]  # (src, dst, label)


class FlowBuilder:
    """
    Deterministic flow builder from AST statements.
    Basic blocks = grouped consecutive non-control statements.
    """

    def __init__(self, file_lines: list[str]):
        self.file_lines = file_lines
        self.nodes: dict[str, dict] = {}
        self.edges: list[tuple[str, str, str]] = []
        self._next_id = 1
        self.loop_stack: list[tuple[str, str]] = []  # (continue_target, break_target)
        self.switch_stack: list[str] = []  # break_target

    def new_node(self, shape: str, label: str, code_text: str = "", line_count: int = 0) -> str:
        """
        NEW: Store code_text and line_count for better role inference and region merging.
        """
        nid = f"n{self._next_id}"
        self._next_id += 1
        clean = clean_label_text(label)
        self.nodes[nid] = {
            "shape": shape,
            "label": clean,
            "role": infer_role(clean, code_text),
            "line_count": line_count,
            "code_text": code_text,  # store for region naming
        }
        return nid

    def add_edge(self, src: str, dst: str, label: str = ""):
        if not src or not dst:
            return
        self.edges.append((src, dst, clean_label_text(label) if label else ""))

    def build_function(self, fn_cursor) -> Graph:
        body = None
        for ch in fn_cursor.get_children():
            if ch.kind == cindex.CursorKind.COMPOUND_STMT:
                body = ch
                break

        if body is None:
            n = self.new_node("process", "No implementation")
            self.add_edge("Start", n)
            self.add_edge(n, "End")
            return Graph(self.nodes, self.edges)

        entry, exits = self.build_compound(body)
        self.add_edge("Start", entry)
        for ex in exits:
            self.add_edge(ex, "End")
        return Graph(self.nodes, self.edges)

    def build_stmt(self, cursor) -> tuple[str, list[str]]:
        k = cursor.kind

        if k == cindex.CursorKind.RETURN_STMT:
            text = cursor_text(cursor, self.file_lines)
            n = self.new_node("process", "Return from function", text, 1)
            return n, []

        if k == cindex.CursorKind.BREAK_STMT:
            n = self.new_node("process", "Break", "", 1)
            if self.switch_stack:
                self.add_edge(n, self.switch_stack[-1])
            elif self.loop_stack:
                self.add_edge(n, self.loop_stack[-1][1])
            return n, []

        if k == cindex.CursorKind.CONTINUE_STMT:
            n = self.new_node("process", "Continue", "", 1)
            if self.loop_stack:
                self.add_edge(n, self.loop_stack[-1][0])
            return n, []

        if k == cindex.CursorKind.IF_STMT:
            return self._build_if(cursor)

        if k in (cindex.CursorKind.FOR_STMT, cindex.CursorKind.WHILE_STMT, cindex.CursorKind.DO_STMT):
            return self._build_loop(cursor)

        if k == cindex.CursorKind.SWITCH_STMT:
            return self._build_switch(cursor)

        if CK_CXX_TRY is not None and k == CK_CXX_TRY:
            return self._build_try(cursor)

        return self.build_compound(cursor)

    def build_compound(self, cursor) -> tuple[str, list[str]]:
        """
        Build flow from a compound statement.
        Groups consecutive non-control statements.
        """
        if cursor is None:
            n = self.new_node("process", "No operation")
            return n, [n]

        if cursor.kind != cindex.CursorKind.COMPOUND_STMT:
            text = cursor_text(cursor, self.file_lines)
            line_count = len(text.splitlines()) if text else 1
            n = self.new_node("process", summarize_block_with_llm(text), text, line_count)
            return n, [n]

        children = list(cursor.get_children())
        entry = None
        curr_exits: list[str] = []
        pending: list = []

        CONTROL_KINDS = {
            cindex.CursorKind.IF_STMT,
            cindex.CursorKind.FOR_STMT,
            cindex.CursorKind.WHILE_STMT,
            cindex.CursorKind.DO_STMT,
            cindex.CursorKind.SWITCH_STMT,
            CK_CXX_TRY,
            cindex.CursorKind.RETURN_STMT,
            cindex.CursorKind.BREAK_STMT,
            cindex.CursorKind.CONTINUE_STMT,
        }
        CONTROL_KINDS = {k for k in CONTROL_KINDS if k is not None}

        def flush_pending():
            nonlocal entry, curr_exits, pending
            if not pending:
                return

            # Split long straight-line code into smaller semantic segments
            segments: list[list] = []
            current: list = []
            current_lines = 0

            for stmt in pending:
                stmt_text = cursor_text(stmt, self.file_lines)
                stmt_lines = max(1, len(stmt_text.splitlines())) if stmt_text else 1

                if (
                    current
                    and (
                        len(current) >= PENDING_SEGMENT_MAX_STMTS
                        or (current_lines + stmt_lines) > PENDING_SEGMENT_MAX_LINES
                    )
                ):
                    segments.append(current)
                    current = []
                    current_lines = 0

                current.append(stmt)
                current_lines += stmt_lines

            if current:
                segments.append(current)

            for seg in segments:
                text = "\n".join(t for t in (cursor_text(s, self.file_lines) for s in seg) if t)
                label = summarize_block_with_llm(text)
                line_count = len(text.splitlines()) if text else 1
                n = self.new_node("process", label, text, line_count)

                if entry is None:
                    entry = n
                if curr_exits:
                    for ex in curr_exits:
                        self.add_edge(ex, n)
                curr_exits = [n]

            pending = []

        # Main walk
        for child in children:
            if child.kind in CONTROL_KINDS:
                flush_pending()
                s_entry, s_exits = self.build_stmt(child)

                if entry is None:
                    entry = s_entry
                if curr_exits:
                    for ex in curr_exits:
                        self.add_edge(ex, s_entry)

                curr_exits = s_exits
            else:
                pending.append(child)

        flush_pending()

        if entry is None:
            n = self.new_node("process", "No operation")
            return n, [n]

        return entry, curr_exits

    def _build_if(self, cursor) -> tuple[str, list[str]]:
        children = list(cursor.get_children())
        cond = children[0] if children else None
        then_stmt = children[1] if len(children) > 1 else None
        else_stmt = children[2] if len(children) > 2 else None

        cond_text = cursor_text(cond, self.file_lines) or "condition"
        cond_label = clean_condition_text(cond_text)
        d = self.new_node("decision", f"Check {cond_label}", cond_text, 1)

        t_entry, t_exits = self.build_compound(then_stmt)
        self.add_edge(d, t_entry, "true")

        if else_stmt:
            f_entry, f_exits = self.build_compound(else_stmt)
            self.add_edge(d, f_entry, "false")
            return d, (t_exits + f_exits)

        # no else: false falls through
        return d, (t_exits + [d])

    def _build_loop(self, cursor) -> tuple[str, list[str]]:
        k = cursor.kind
        children = list(cursor.get_children())

        cond = None
        body = None
        if k == cindex.CursorKind.WHILE_STMT:
            cond = children[0] if len(children) > 0 else None
            body = children[1] if len(children) > 1 else None
        elif k == cindex.CursorKind.DO_STMT:
            body = children[0] if len(children) > 0 else None
            cond = children[1] if len(children) > 1 else None
        else:  # FOR
            cond = children[1] if len(children) > 1 else None
            body = children[-1] if children else None

        cond_text = cursor_text(cond, self.file_lines) or "loop condition"
        cond_label = clean_condition_text(cond_text)
        check = self.new_node("decision", f"Check {cond_label}", cond_text, 1)
        after = self.new_node("process", "After loop", "", 1)

        self.loop_stack.append((check, after))
        b_entry, b_exits = self.build_compound(body)
        self.loop_stack.pop()

        if k == cindex.CursorKind.DO_STMT:
            entry = b_entry
            for ex in b_exits:
                self.add_edge(ex, check)
            self.add_edge(check, b_entry, "true")
            self.add_edge(check, after, "false")
            return entry, [after]

        self.add_edge(check, b_entry, "true")
        self.add_edge(check, after, "false")
        for ex in b_exits:
            self.add_edge(ex, check)
        return check, [after]

    def _build_switch(self, cursor) -> tuple[str, list[str]]:
        children = list(cursor.get_children())
        expr = children[0] if children else None
        body = children[1] if len(children) > 1 else None

        expr_text = cursor_text(expr, self.file_lines) or "expression"
        expr_label = clean_condition_text(expr_text)
        d = self.new_node("decision", f"Switch on {expr_label}", expr_text, 1)
        after = self.new_node("process", "After switch", "", 1)

        self.switch_stack.append(after)

        cases = []
        default_case = None
        if body:
            for ch in body.get_children():
                if ch.kind == cindex.CursorKind.CASE_STMT:
                    cases.append(ch)
                elif ch.kind == cindex.CursorKind.DEFAULT_STMT:
                    default_case = ch

        built: list[tuple[str, str, list[str]]] = []
        for c in cases:
            raw = cursor_text(c, self.file_lines)
            case_label = clean_label_text(raw.split(":")[0] if ":" in raw else "case")
            c_children = list(c.get_children())
            c_body = c_children[-1] if c_children else None
            entry, exits = self.build_compound(c_body)
            built.append((case_label, entry, exits))

        if default_case:
            d_children = list(default_case.get_children())
            d_body = d_children[-1] if d_children else None
            entry, exits = self.build_compound(d_body)
            built.append(("default", entry, exits))

        for lbl, entry, _ in built:
            self.add_edge(d, entry, lbl)

        # Best-effort fallthrough
        for i in range(len(built) - 1):
            next_entry = built[i + 1][1]
            for ex in built[i][2]:
                self.add_edge(ex, next_entry, "fallthrough")

        if built:
            for ex in built[-1][2]:
                self.add_edge(ex, after)
        else:
            self.add_edge(d, after, "default")

        self.switch_stack.pop()
        return d, [after]

    def _build_try(self, cursor) -> tuple[str, list[str]]:
        children = list(cursor.get_children())
        try_block = children[0] if children else None
        catches = children[1:] if len(children) > 1 else []

        if CK_CXX_CATCH is not None:
            catches = [c for c in catches if c.kind == CK_CXX_CATCH] or catches

        decision = self.new_node("decision", "Exception occurs", "", 1)
        after = self.new_node("process", "After try catch", "", 1)

        t_entry, t_exits = self.build_compound(try_block)
        self.add_edge(decision, t_entry, "no")
        for ex in t_exits:
            self.add_edge(ex, after)

        if catches:
            catch_text = "\n".join(t for t in (cursor_text(c, self.file_lines) for c in catches) if t)
            catch_label = summarize_block_with_llm(catch_text) if catch_text else "Handle exception"
            line_count = len(catch_text.splitlines()) if catch_text else 1
            c_node = self.new_node("process", catch_label, catch_text, line_count)
            self.add_edge(decision, c_node, "yes")
            self.add_edge(c_node, after)
        else:
            self.add_edge(decision, after, "yes")

        return decision, [after]


def _can_merge_regions(curr_node: dict, next_node: dict, total_lines: int) -> bool:
    """
    Decide if two consecutive PROCESS nodes can be merged.
    Merges are liberal for straight-line code, but we stop at
    finalize/error boundaries to keep important steps explicit.
    """
    if not curr_node or not next_node:
        return False
    if curr_node.get("shape") != "process" or next_node.get("shape") != "process":
        return False

    curr_role = curr_node.get("role", SemanticRole.COMPUTE)
    next_role = next_node.get("role", SemanticRole.COMPUTE)

    if curr_role in (SemanticRole.ERROR, SemanticRole.FINALIZE):
        return False
    if next_role in (SemanticRole.ERROR, SemanticRole.FINALIZE):
        return False

    next_lines = next_node.get("line_count", 0)
    if total_lines + next_lines > MAX_REGION_LINES:
        return False

    return True


def build_regions(graph: Graph) -> list[Region]:
    """
    NEW: Improved semantic region merging.
    
    Rules:
    1. Merge consecutive PROCESS nodes with same role
    2. Respect MAX_REGION_NODES limit (prevent over-merging)
    3. Respect MAX_REGION_LINES limit (prevent huge blocks)
    4. NEVER merge DECISION nodes (always keep separate)
    5. Stop merging when role changes or branching occurs
    """
    indeg = defaultdict(int)
    out = defaultdict(list)

    for src, dst, _ in graph.edges:
        if src in ("Start", "End") or dst in ("Start", "End"):
            continue
        indeg[dst] += 1
        out[src].append(dst)

    visited = set()
    regions: list[Region] = []
    rid = 1

    # Sort nodes by topological order (approximate: by node ID)
    sorted_nodes = sorted(graph.nodes.keys(), key=lambda x: int(x[1:]) if x[1:].isdigit() else 0)

    process_nodes = [n for n in sorted_nodes if graph.nodes.get(n, {}).get("shape") == "process"]
    # Adaptive limits: if straight-line code is long, allow slightly larger regions
    adaptive_max_nodes = MAX_REGION_NODES
    adaptive_max_lines = MAX_REGION_LINES
    if len(process_nodes) >= 20:
        adaptive_max_nodes = min(10, MAX_REGION_NODES + 2)
        adaptive_max_lines = min(45, MAX_REGION_LINES + 10)

    for nid in sorted_nodes:
        if nid in visited:
            continue

        node = graph.nodes[nid]
        role = node["role"]
        shape = node["shape"]

        # Decision nodes: NEVER merge (single node region)
        if shape == "decision":
            regions.append(Region(
                id=f"R{rid}",
                nodes=[nid],
                role=SemanticRole.VALIDATION,
                shape="decision",
                entry=nid,
                exits=[nid],
                line_count=node.get("line_count", 1)
            ))
            visited.add(nid)
            rid += 1
            continue

        # Process nodes: attempt to merge forward in a linear chain
        chain = [nid]
        visited.add(nid)
        total_lines = node.get("line_count", 0)
        curr = nid

        while len(chain) < adaptive_max_nodes:
            # Check if we can merge forward
            nxts = out.get(curr, [])
            if len(nxts) != 1:  # branching or end
                break

            nxt = nxts[0]
            if nxt in visited:
                break

            nxt_node = graph.nodes.get(nxt, {})
            nxt_shape = nxt_node.get("shape", "")
            nxt_lines = nxt_node.get("line_count", 0)

            # Stop conditions:
            if nxt_shape != "process":  # don't merge decisions
                break
            if indeg.get(nxt, 0) != 1:  # multiple incoming edges
                break
            if not _can_merge_regions(graph.nodes.get(curr), nxt_node, total_lines):
                break

            # Merge
            chain.append(nxt)
            visited.add(nxt)
            total_lines += nxt_lines
            curr = nxt

        regions.append(Region(
            id=f"R{rid}",
            nodes=chain,
            role=role,
            shape="process",
            entry=chain[0],
            exits=[chain[-1]],
            line_count=total_lines
        ))
        rid += 1

    return regions


def name_region_with_llm(region: Region, graph: Graph) -> str:
    """
    NEW: Improved region naming with semantic focus.
    
    For single-node regions: use existing label.
    For multi-node regions: ask LLM to synthesize a semantic name.
    """
    labels = [graph.nodes[n]["label"] for n in region.nodes]

    if len(labels) == 1:
        label = labels[0]
        if _is_code_like(label):
            refined = _rewrite_label_semantic(label)
            return refined or label
        return label

    # For multi-node regions: get a semantic synthesis
    # NEW PROMPT: Focus on high-level goal
    prompt = (
        "You are naming a flowchart block that represents multiple related steps.\n"
        "Goal: Describe the HIGH-LEVEL purpose of these steps together.\n"
        "\n"
        "Rules:\n"
        "- Output ONE phrase (3 to 8 words)\n"
        "- Describe WHAT is achieved overall, not the individual steps\n"
        "- Synthesize a meaningful name that captures the shared goal\n"
        "- Bad: 'Initialize and compute' → Good: 'Setup computation parameters'\n"
        "- Bad: 'Call helper and output' → Good: 'Transform and display result'\n"
        "- No punctuation\n"
        "- ASCII only\n"
        "\n"
        "Individual steps:\n"
        + "\n".join(f"  {i+1}. {l}" for i, l in enumerate(labels))
        + "\n\n"
        "High-level name:"
    )

    try:
        resp = llm.invoke([HumanMessage(prompt)])
        name = clean_label_text(resp.content)
        return name or labels[0]
    except Exception:
        # Fallback: join first and last
        if len(labels) >= 2:
            return f"{labels[0]} then {labels[-1]}"
        return labels[0]


def render_abstract_mermaid(graph: Graph, regions: list[Region]) -> str:
    """
    Render region-level (abstract/semantic) Mermaid flowchart.
    This is what the user wants: fewer boxes, semantic grouping.
    """
    lines = ["flowchart TD", "Start((Start))"]

    # Map CFG node → region
    node_to_region = {}
    for r in regions:
        for n in r.nodes:
            node_to_region[n] = r.id

    # Render region nodes
    for r in regions:
        label = clean_label_text(r.label or r.id)

        if r.shape == "decision":
            lines.append(f"{r.id}{{{{{label}}}}}")
        else:
            lines.append(f"{r.id}[{label}]")

    lines.append("End((End))")

    # Render region-level edges
    added_edges = set()
    for src, dst, _ in graph.edges:
        if src in ("Start", "End") or dst in ("Start", "End"):
            continue

        rs = node_to_region.get(src)
        rd = node_to_region.get(dst)

        if not rs or not rd or rs == rd:
            continue

        edge = (rs, rd)
        if edge not in added_edges:
            lines.append(f"{rs} --> {rd}")
            added_edges.add(edge)

    # Connect Start and End
    if regions:
        lines.append(f"Start --> {regions[0].id}")
        lines.append(f"{regions[-1].id} --> End")

    return "\n".join(lines) + "\n"


def render_mermaid(graph: Graph) -> str:
    """Render detailed (CFG-level) Mermaid flowchart."""
    lines = ["flowchart TD", "Start((Start))"]

    for nid, node in graph.nodes.items():
        shape = node["shape"]
        label = clean_label_text(node["label"])

        if shape == "decision":
            lines.append(f"{nid}{{{{{label}}}}}")
        else:
            lines.append(f"{nid}[{label}]")

    lines.append("End((End))")

    for src, dst, lbl in graph.edges:
        if lbl:
            lines.append(f"{src} --> |{clean_label_text(lbl)}| {dst}")
        else:
            lines.append(f"{src} --> {dst}")

    return "\n".join(lines) + "\n"


def validate_mermaid(mermaid: str) -> tuple[bool, Optional[str]]:
    if not mermaid or not mermaid.strip():
        return False, "Empty flowchart"
    if "flowchart" not in mermaid.lower():
        return False, "Missing flowchart declaration"
    if "Start((Start))" not in mermaid:
        return False, "Missing Start node"
    if "End((End))" not in mermaid:
        return False, "Missing End node"
    if "&#" in mermaid:
        return False, "HTML entities detected"
    for line in mermaid.splitlines():
        if line.count("-->") > 1:
            return False, "Multiple edges in one line"
    return True, None


def generate_flowchart_for_function(fn_cursor, file_lines: list[str]):
    """
    Generate flowcharts for a function.
    
    Returns:
    1) flowcharts: dict {"detailed": str, "abstract": str}
    2) images: dict {"detailed": str|None, "abstract": str|None}
    3) feedback: Optional[str]
    """
    feedback = None

    # Build CFG
    builder = FlowBuilder(file_lines)
    graph = builder.build_function(fn_cursor)

    detailed_mermaid = render_mermaid(graph)

    ok, err = validate_mermaid(detailed_mermaid)
    if not ok:
        return (
            {"detailed": detailed_mermaid, "abstract": None},
            {"detailed": None, "abstract": None},
            f"Detailed flowchart validation failed: {err}",
        )

    # Build semantic regions (NEW)
    regions = build_regions(graph)

    # Name regions with LLM (NEW)
    for region in regions:
        region.label = name_region_with_llm(region, graph)

    # Render abstract (semantic) Mermaid
    abstract_mermaid = render_abstract_mermaid(graph, regions)

    ok2, err2 = validate_mermaid(abstract_mermaid)
    if not ok2:
        return (
            {"detailed": detailed_mermaid, "abstract": abstract_mermaid},
            {"detailed": None, "abstract": None},
            f"Abstract flowchart validation failed: {err2}",
        )

    # Generate images
    img_detailed = None
    img_abstract = None

    currdir = os.getcwd()
    try:
        os.chdir(mermaid_path)

        subprocess.check_output(
            ["node", "index.js", detailed_mermaid, f"{fn_cursor.spelling}_detailed.png"],
            stderr=subprocess.STDOUT,
            timeout=30,
        )
        img_detailed = os.path.join(mermaid_path, f"{fn_cursor.spelling}_detailed.png")

        subprocess.check_output(
            ["node", "index.js", abstract_mermaid, f"{fn_cursor.spelling}_abstract.png"],
            stderr=subprocess.STDOUT,
            timeout=30,
        )
        img_abstract = os.path.join(mermaid_path, f"{fn_cursor.spelling}_abstract.png")

    except Exception as e:
        feedback = f"Mermaid image generation failed: {str(e)[:200]}"
    finally:
        os.chdir(currdir)

    return (
        {"detailed": detailed_mermaid, "abstract": abstract_mermaid},
        {"detailed": img_detailed, "abstract": img_abstract},
        feedback,
    )


def generate_function_description(function_lines: list[str]) -> str:
    prompt = (
        "You are a C++ code documentation expert.\n"
        "Provide a concise 2-3 sentence description.\n"
        "Do not invent anything.\n\n"
        "Function:\n"
        "{function}\n"
        "Description:"
    )
    query = prompt.format(function="\n".join(function_lines[:120]))
    try:
        resp = llm.invoke([HumanMessage(query)])
        return clean_unicode_chars(resp.content).strip()
    except Exception:
        return "Description generation failed"


def extract_node_info(fn_cursor, file_path: str, module_name: str) -> Optional[dict]:
    extent = fn_cursor.extent
    try:
        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
            file_lines = f.readlines()

        function_lines = extract_source_lines(file_lines, extent.start.line, extent.end.line)
        function_lines = [l.rstrip() for l in function_lines if l.strip()]
        if not function_lines:
            return None

        flowchart_dict, img_dict, feedback = generate_flowchart_for_function(fn_cursor, file_lines)

        # Prefer abstract (semantic) flowchart
        flowchart = flowchart_dict.get("abstract") or flowchart_dict.get("detailed")
        img = img_dict.get("abstract") or img_dict.get("detailed")

        return {
            "uid": node_uid(fn_cursor),
            "name": fn_cursor.spelling,
            "line_start": extent.start.line,
            "column_start": extent.start.column,
            "line_end": extent.end.line,
            "column_end": extent.end.column,
            "file_name": file_path,
            "module_name": module_name,
            "description": generate_function_description(function_lines),
            "flowchart": flowchart,
            "feedback": feedback,
            "img": img,
            "callees": [],
            "callers": [],
        }
    except Exception as e:
        print(f"[WARN] extract_node_info failed for {fn_cursor.spelling}: {e}")
        return None


def visit(cursor, file_path: str, module_name: str, nodes: dict, call_edges, current_fn_uid: Optional[str], visited=None):
    if visited is None:
        visited = set()

    if cursor.location.file and cursor.location.file.name != file_path:
        return

    fqn = f"{module_name}::{file_path}::{cursor.spelling}"
    if fqn in visited:
        return

    if cursor.is_definition() and cursor.kind in (
        cindex.CursorKind.FUNCTION_DECL,
        cindex.CursorKind.CXX_METHOD,
        cindex.CursorKind.CONSTRUCTOR,
        cindex.CursorKind.DESTRUCTOR,
    ):
        visited.add(fqn)
        uid = node_uid(cursor)
        if uid not in nodes and cursor.spelling:
            info = extract_node_info(cursor, file_path, module_name)
            if info:
                nodes[uid] = info
                current_fn_uid = uid

    if cursor.kind == cindex.CursorKind.CALL_EXPR and current_fn_uid:
        ref = cursor.referenced
        if ref and ref.spelling and ref.location.file:
            callee_uid = node_uid(ref)
            call_edges[current_fn_uid].add(callee_uid)

    for child in cursor.get_children():
        visit(child, file_path, module_name, nodes, call_edges, current_fn_uid, visited)


def generate_word_document(data: list[dict], doc_name: str):
    doc = Document()
    for index, item in enumerate(data, start=1):
        doc.add_heading(f"1.1.{index} {item['name']}", level=1)
        table = doc.add_table(rows=2, cols=2, style="Table Grid")
        table.rows[0].cells[0].text = "Requirement ID"
        table.rows[0].cells[1].text = f"SAVV8-SwU-{index}"
        table.rows[1].cells[0].text = "Flowchart"

        if item.get("img") and os.path.exists(item["img"]):
            table.rows[1].cells[1].add_paragraph().add_run().add_picture(item["img"], width=Inches(6.0))
        else:
            table.rows[1].cells[1].text = item.get("feedback") or "Flowchart image not available"

    os.makedirs(os.path.dirname(doc_name), exist_ok=True)
    doc.save(doc_name)


def parse_file(index, file_path: str, root_dir: str, compile_args: list[str], out_nodes: dict, out_edges):
    module_name = get_module_name(file_path, root_dir)
    tu = index.parse(
        file_path,
        args=compile_args,
        options=cindex.TranslationUnit.PARSE_DETAILED_PROCESSING_RECORD,
    )

    my_nodes: dict = {}
    my_edges = defaultdict(set)
    visit(tu.cursor, file_path, module_name, my_nodes, my_edges, None)

    if not my_nodes:
        return

    base = os.path.splitext(os.path.basename(file_path))[0]
    meta_name = base
    if meta_name in out_nodes:
        meta_name = f"{meta_name}_{len(out_nodes)}"

    json_path = os.path.join(out_dir, f"{meta_name}.json")
    docx_path = os.path.join(out_dir, f"{base}.docx")

    generate_word_document(list(my_nodes.values()), docx_path)
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(list(my_nodes.values()), f, indent=2, ensure_ascii=False)

    out_nodes.update(my_nodes)
    out_edges.update(my_edges)


def parse_codebase(root_dir: str, compile_args: Optional[list[str]] = None) -> list[dict]:
    compile_args = compile_args or ["-std=c++17"]
    index = cindex.Index.create()
    nodes: dict = {}
    call_edges = defaultdict(set)

    for root, _, files in os.walk(root_dir):
        for f in files:
            if is_cpp_file(f):
                path = os.path.join(root, f)
                try:
                    parse_file(index, path, root_dir, compile_args, nodes, call_edges)
                except Exception as e:
                    print(f"[WARN] Failed to parse {path}: {e}")

    return list(nodes.values())


def main():
    parser = argparse.ArgumentParser(description="Generate AST-driven flowcharts for C++ functions")
    parser.add_argument("path", help="C++ codebase root directory")
    parser.add_argument("--std", default="c++17", help="C++ standard, e.g. c++17, c++20")
    parser.add_argument("--libclang", help="Path to libclang shared library")
    args = parser.parse_args()

    if args.libclang:
        cindex.Config.set_library_file(args.libclang)

    os.makedirs(out_dir, exist_ok=True)
    parse_codebase(args.path, compile_args=[f"-std={args.std}"])
    print("Done.")


if __name__ == "__main__":
    main()
